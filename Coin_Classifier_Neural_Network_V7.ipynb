{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6ec2553ab0f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n",
    "pip install keras\n",
    "pip install sys\n",
    "pip install os\n",
    "pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, BatchNormalization, Dropout, Flatten, Dense, Activation, Conv2D, merge\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras import callbacks\n",
    "import time\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_APPLICATION_CREDENTIALS='C:/Users/Rishabh Patni/Desktop/Projects/Keras Coin-eaf1b6df7b08.json'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "  from google.colab import auth as google_auth\n",
    "  google_auth.authenticate_user()\n",
    "\n",
    "# If you are running this notebook locally, replace the string below with the\n",
    "# path to your service account key and run this cell to authenticate your GCP\n",
    "# account.\n",
    "else:\n",
    "  %env GOOGLE_APPLICATION_CREDENTIALS 'C:/Users/Rishabh Patni/Desktop/Projects/Keras Coin-eaf1b6df7b08.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "IMG_WIDTH, IMG_HEIGHT = 400, 400\n",
    "BATCH_SIZE = 173\n",
    "samples_per_epoch = 6228\n",
    "validation_steps = 300\n",
    "nb_filters1 = 32\n",
    "nb_filters2 = 64\n",
    "nb_filters3 = 128\n",
    "nb_filters4 = 256\n",
    "conv1_size = 7\n",
    "conv2_size = 5\n",
    "conv3_size = 3\n",
    "conv4_size = 3\n",
    "conv5_size = 1\n",
    "pool_size = 2\n",
    "classes_num = 211\n",
    "lr = 0.01\n",
    "epochs = 200\n",
    "decay_rate = lr/epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e0c610be5263>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Validation Set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimage_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata_dir_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:/Users/Rishabh Patni/Desktop/Projects/Coin-Identifier/Training Images/validation/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "#Validation Set\n",
    "image_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "data_dir_2 = \"C:/Users/Rishabh Patni/Desktop/Projects/Coin-Identifier/Training Images/validation/\"\n",
    "data_2 = pathlib.Path(data_dir_2)\n",
    "CLASS_NAMES_1 = np.array([item.name for item in data_2.glob('dir/*')])\n",
    "validation_data_gen = image_generator.flow_from_directory(directory = data_dir_2, \n",
    "                                                     batch_size = BATCH_SIZE, \n",
    "                                                     shuffle = False, \n",
    "                                                     classes = list(CLASS_NAMES_1),\n",
    "                                                     target_size = \n",
    "                                                     (IMG_HEIGHT, IMG_WIDTH), \n",
    "                                                     color_mode = \"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6228 images belonging to 211 classes.\n"
     ]
    }
   ],
   "source": [
    "#Training Set\n",
    "image_generator_training = ImageDataGenerator(rescale=1./255, \n",
    "                                     rotation_range=10,\n",
    "                                     zoom_range=0.05)\n",
    "\n",
    "data_dir = \"C:/Users/Rishabh Patni/Desktop/Projects/Coin-Identifier/Training Images/train/\"\n",
    "data = pathlib.Path(data_dir)\n",
    "CLASS_NAMES = np.array([item.name for item in data.glob('dir/*')])\n",
    "train_data_gen = image_generator_training.flow_from_directory(directory = data_dir, \n",
    "                                                     batch_size = BATCH_SIZE, \n",
    "                                                     shuffle = True, \n",
    "                                                     classes = list(CLASS_NAMES),\n",
    "                                                     target_size = \n",
    "                                                     (IMG_HEIGHT, IMG_WIDTH), \n",
    "                                                     color_mode = \"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 400, 400, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 400, 400, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 400, 400, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 200, 200, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 200, 200, 32) 4128        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 200, 200, 32) 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 200, 200, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 200, 200, 32) 4128        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200, 200, 32) 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 200, 200, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200, 200, 64) 0           activation_3[0][0]               \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 100, 100, 64) 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 100, 100, 64) 36928       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 100, 100, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 100, 100, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 100, 100, 64) 36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 100, 100, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 100, 100, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 100, 100, 64) 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 100, 100, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 100, 100, 64) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 100, 100, 128 0           activation_6[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 50, 50, 128)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 50, 50, 128)  147584      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 50, 50, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 50, 50, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 50, 50, 128)  147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 50, 50, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 50, 50, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 50, 50, 128)  65664       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 50, 50, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 50, 50, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 50, 50, 256)  0           activation_9[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 25, 25, 256)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 160000)       0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 211)          33760211    flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 34,243,539\n",
      "Trainable params: 34,242,259\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Model Development ##\n",
    "# First Layer (Visible)\n",
    "visible = Input(shape = (IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "# Second Layer\n",
    "a= Conv2D(32, kernel_size = (3, 3), \n",
    "          padding =\"same\") (visible)\n",
    "a= Activation(\"relu\")(a)\n",
    "a = MaxPooling2D(pool_size=(2, 2)) (a)\n",
    "\n",
    "shortcut_a2 = a\n",
    "\n",
    "# Second Layer (re-run with 32 filters)\n",
    "a = Conv2D(32, kernel_size = (2, 2), padding =\"same\") (a)\n",
    "a = BatchNormalization()(a)\n",
    "a = Activation(\"relu\") (a)\n",
    "\n",
    "# Second Layer (re-run with 32 filters)\n",
    "a = Conv2D(32, kernel_size = (2, 2), padding =\"same\") (a)\n",
    "a = BatchNormalization()(a)\n",
    "a = Activation(\"relu\") (a)\n",
    "a = keras.layers.concatenate([a, shortcut_a2])\n",
    "a = MaxPooling2D(pool_size=(2, 2)) (a)\n",
    "\n",
    "\n",
    "\n",
    "# Third Layer (64 Filters)\n",
    "a = Conv2D(64, kernel_size = (3, 3), padding =\"same\") (a)\n",
    "a = BatchNormalization()(a)\n",
    "a = Activation(\"relu\") (a)\n",
    "\n",
    "shortcut_a3 = a\n",
    "\n",
    "# Third Layer (Re-run with 64 Filters)\n",
    "a = Conv2D(64, kernel_size = (3, 3), padding =\"same\") (a)\n",
    "a = BatchNormalization()(a)\n",
    "a = Activation(\"relu\") (a)\n",
    "\n",
    "# Third Layer (Re-run with 64 Filters)\n",
    "a = Conv2D(64, kernel_size = (3, 3), padding =\"same\") (a)\n",
    "a = BatchNormalization()(a)\n",
    "a = Activation(\"relu\") (a)\n",
    "a = keras.layers.concatenate([a, shortcut_a3])\n",
    "a = MaxPooling2D(pool_size=(2, 2)) (a)\n",
    "\n",
    "\n",
    "\n",
    "# Fourth Layer (128 Filters)\n",
    "a = Conv2D(128, kernel_size = (3, 3), padding =\"same\") (a)\n",
    "a = BatchNormalization()(a)\n",
    "a = Activation(\"relu\") (a)\n",
    "\n",
    "shortcut_a4 = a\n",
    "\n",
    "# Fourth Layer (Re-run with 128 Filters)\n",
    "a = Conv2D(128, kernel_size = (3, 3), padding =\"same\") (a)\n",
    "a = BatchNormalization()(a)\n",
    "a = Activation(\"relu\") (a)\n",
    "\n",
    "# Fourth layer (Re-run with 128 Filters)\n",
    "a = Conv2D(128, kernel_size = (2, 2), padding =\"same\") (a)\n",
    "a = BatchNormalization()(a)\n",
    "a = Activation(\"relu\")(a)\n",
    "a = keras.layers.concatenate([a, shortcut_a4])\n",
    "a = MaxPooling2D(pool_size=(2, 2), strides = None) (a)\n",
    "\n",
    "# Consolidating and Output\n",
    "a = Flatten()(a)\n",
    "output = Dense(classes_num, activation='softmax') (a)\n",
    "model = Model(inputs = visible, outputs = output)\n",
    "print(model.summary())\n",
    "\n",
    "#Defining Optimizer\n",
    "Optimize = keras.optimizers.Adam (learning_rate = lr, decay = decay_rate)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Optimize, \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Creating Checkpoint measure\n",
    "filepath = 'C:/Users/Rishabh Patni/Desktop/Projects/Coin-Identifier/V7/coin.h5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', save_weights_only = False,\n",
    "                                             verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d0fdb321f2df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#fitting data to model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m model.fit_generator(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_data_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#fitting data to model\n",
    "model.fit_generator(\n",
    "    train_data_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_data_gen,\n",
    "    callbacks = callbacks_list, \n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "#Save model\n",
    "model.save('C:/Users/Rishabh Patni/Desktop/Projects/Coin-Identifier/V7/coin.h5')\n",
    "model.save_weights('C:/Users/Rishabh Patni/Desktop/Projects/Coin-Identifier/V7/coinweights.h5')\n",
    "\n",
    "#Calculate execution time\n",
    "end = time.time()\n",
    "dur = end-start\n",
    "print(dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 844 images belonging to 211 classes.\n"
     ]
    }
   ],
   "source": [
    "# testing set\n",
    "data_dir_3 = \"C:/Users/Rishabh Patni/Desktop/Projects/Coin-Identifier/Training Images/test/\"\n",
    "data_3 = pathlib.Path(data_dir_3)\n",
    "CLASS_NAMES_2 = np.array([item.name for item in data_3.glob('dir/*')])\n",
    "test_data_gen = image_generator.flow_from_directory(directory = data_dir_3, \n",
    "                                                     batch_size = BATCH_SIZE, \n",
    "                                                     shuffle = True, \n",
    "                                                     classes = list(CLASS_NAMES_2),\n",
    "                                                     target_size = \n",
    "                                                     (IMG_HEIGHT, IMG_WIDTH), \n",
    "                                                     color_mode = \"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 18s 1s/step\n",
      "test loss, test acc: [1.9074764251708984, 0.7523696422576904]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "results = model.evaluate(test_data_gen)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_APPLICATION_CREDENTIALS=''\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  from google.colab import auth as google_auth\n",
    "  google_auth.authenticate_user()\n",
    "else:\n",
    "  %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
